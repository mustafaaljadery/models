{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRUs\n",
    "- They're the next innovation after LSTMs but before Transformers.\n",
    "- They are an adaptation of RNNs, similar to LSTMs\n",
    "- They have less tensor operators so they are speedier to train. \n",
    "- You can think of them as LSTMs without the short term memory, but they do more operations to the long term memory.\n",
    "- Researchers try both LSTMs and GRUs to see what works better for their usecase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, bias=True):\n",
    "        super(Cell, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bias = bias\n",
    "\n",
    "        self.input = nn.Linear(input_size, 3 * hidden_size, bias=bias)\n",
    "        self.hidden = nn.Linear(hidden_size, 3 * hidden_size, bias=bias)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        std = 1.0 / np.sqrt(self.hidden_size)\n",
    "        for w in self.parameters():\n",
    "            w.data.uniform_(-std,std)\n",
    "\n",
    "    def forward(self, input, hx=None):\n",
    "        if hx = None:\n",
    "            hx = Variable(input.new_zeros(input.size(0), self.hidden_size))\n",
    "        \n",
    "        xt = self.input(input)\n",
    "        ht = self.hidden(hx)\n",
    "\n",
    "        x_reset, x_upd, x_new = x_t.chunk(3, 1)\n",
    "        h_reset, h_upd, h_new = h_t.chunk(3, 1)\n",
    "\n",
    "        reset_gate = torch.sigmoid(x_reset + h_reset)\n",
    "        update_gate = torch.sigmoid(x_upd + h_upd)\n",
    "        new_gate = torch.tanh(x_new + (reset_gate * h_new))\n",
    "\n",
    "        hy = update_gate * hx + (1 - update_gate) * new_gate\n",
    "\n",
    "        return hy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, bias, output_size):\n",
    "        super(GRU, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.bias = bias\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.rnn_cell_list = nn.ModuleList()\n",
    "        self.rnn_cell_list.append(Cell(self.input_size, self.hidden_size, self.bias))\n",
    "\n",
    "        for l in range(1,self.num_layers):\n",
    "            self.rnn_cell_list.append(Cell(self.hidden_size, self.hidden_size, self.bias))\n",
    "        \n",
    "        self.fc = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hx=None):\n",
    "        if hx is None: \n",
    "            h0 = Variable(torch.zeros(self.num_layers, input.size(0), self.hidden_size).to(\"mps\"))\n",
    "        else: \n",
    "            h0 = hx\n",
    "\n",
    "        outs = []\n",
    "        hidden = list()\n",
    "\n",
    "        for layer in range(self.num_layers):\n",
    "            hidden.append(h0[layer, :, :])\n",
    "\n",
    "        for t in range(input.size(1)):\n",
    "            for layer in range(self.num_layers):\n",
    "                if layer == 0:\n",
    "                    hidden_l = self.rnn_cell_list[layer](input[:, t, :], hidden[layer])\n",
    "                else:\n",
    "                    hidden_l = self.rnn_cell_list[layer](hidden[layer - 1],hidden[layer])\n",
    "                hidden[layer] = hidden_l\n",
    "                hidden[layer] = hidden_l\n",
    "            outs.append(hidden_l)\n",
    "\n",
    "        out = outs[-1].squeeze()\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
